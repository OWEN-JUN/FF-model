{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WxZz4Hbw29G-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn4rvAct8Don"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qp81s3zV2_2e"
      },
      "outputs": [],
      "source": [
        "x_pos=torch.tensor([[1,2,3],[3,2,1],[5,6,5]]).type(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwlPMNxJ3PyB",
        "outputId": "23785ec3-6100-46cd-ed2c-d405048cfbba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 4.6667,  4.6667, 28.6667])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_pos.pow(2).mean(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aj6Sy0yoACm3"
      },
      "outputs": [],
      "source": [
        "def base_loss(X_pos: torch.Tensor, X_neg: torch.Tensor, th: float) -> torch.Tensor:\n",
        "    \"\"\"Base loss described in the paper. Log(1+exp(x)) is added to help differentiation.\n",
        "    Args:\n",
        "        X_pos (torch.Tensor): batch of positive model predictions\n",
        "        X_neg (torch.Tensor): batch of negative model predictions\n",
        "        th (float): loss function threshold\n",
        "    Returns:\n",
        "        torch.Tensor: output loss\n",
        "    \"\"\"\n",
        "    logits_pos = X_pos.pow(2).mean(dim=1)\n",
        "    logits_neg = X_neg.pow(2).mean(dim=1)\n",
        "\n",
        "    loss_pos = - logits_pos + th\n",
        "    loss_neg = logits_neg - th\n",
        "\n",
        "    loss_poss = torch.log(1 + torch.exp(loss_pos)).mean()\n",
        "    loss_neg = torch.log(1 + torch.exp(loss_neg)).mean()\n",
        "\n",
        "    loss = loss_poss + loss_neg\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4VUw60KCSFW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tEPisYze3TPg"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Tuple\n",
        "from torch.nn import Linear\n",
        "\n",
        "class FFLinear(Linear):\n",
        "    \"Forward-Forward-layer\"\n",
        "\n",
        "    def __init__(self, input_features:int, output_features:int, activation:torch.nn, \n",
        "                 optimizer:torch.optim, layer_optim_learning_rate: float, threshold:float, loss_fn:Callable, bias:bool = True):\n",
        "        super(FFLinear, self).__init__(input_features, output_features, bias)\n",
        "\n",
        "        self.activation = activation\n",
        "        self.optimizer = optimizer(self.parameters(), lr = layer_optim_learning_rate)\n",
        "        self.threshold = threshold\n",
        "        self.loss_fn = loss_fn\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor: \n",
        "\n",
        "        x = x / (x.norm(2,1, keepdim=True) + 1e-8)\n",
        "\n",
        "        return self.activation(torch.mm(x, self.weight.T) + self.bias.unsqueeze(0))\n",
        "\n",
        "\n",
        "    def train_layer(self, X_pos, X_neg, before : bool) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
        "        \n",
        "        X_pos_out = self.forward(X_pos)\n",
        "        X_neg_out = self.forward(X_neg)\n",
        "\n",
        "\n",
        "        loss = self.loss_fn(X_pos_out, X_neg_out, self.threshold)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "            # 학습후 output을 전달할 것인지, 학습전 output을 전달할 것인지\n",
        "        if before:\n",
        "            return X_pos_out.detach(), X_neg_out.detach(), loss.item()\n",
        "        else:\n",
        "            return self.forward(X_pos).detach(), self.forward(X_neg).detach(), loss.item() \n",
        "\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H2f3G6cGZM_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSPa1QE0OvCG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRtnVkuwfnyX",
        "outputId": "18332a06-6106-4732-8329-e453c6f324f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "784 512\n",
            "1\n",
            "512 512\n"
          ]
        }
      ],
      "source": [
        "hidden_dimensions = [784, 512, 512]\n",
        "for i in range(len(hidden_dimensions) - 1):\n",
        "    print(i)\n",
        "    print(hidden_dimensions[i],hidden_dimensions[i+1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kH97ky5F8bPG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 5292391.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 28917568.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3779307.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4551010.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pickle import FALSE\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torchvision.transforms import Compose, ToTensor, Lambda, Normalize\n",
        "# MNIST dataset\n",
        "transform = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.1307,), (0.3081,)),\n",
        "    Lambda(lambda x: torch.flatten(x))])\n",
        "\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transform,\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=False,\n",
        "                          transform=transform,\n",
        "                          download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8oc0kMfUPWxD"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# dataset loader\n",
        "data_loader = DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=1024, # 배치 크기는 100\n",
        "                                          shuffle=True)\n",
        "test_loader = DataLoader(dataset=mnist_test,\n",
        "                                          batch_size=1024, # 배치 크기는 100\n",
        "                                          shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oJbsRkVNPd0l"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(data_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMWFMIg6PhQN",
        "outputId": "13b36032-2ee8-4586-c1c2-e9ca11725bfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1024, 784])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bq1ycf6IBmn",
        "outputId": "921dac2b-aae6-42e2-aae9-ef1b1116120c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1024, 784])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images, labels = next(iter(test_loader))\n",
        "images.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "QLS1U_NpP5KH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "def generate_positive_negative_samples_overlay(X: torch.Tensor, Y: torch.Tensor, only_positive: bool):\n",
        "    \"\"\"Generate positive and negative samples using labels. It overlays labels in input. For neg it does\n",
        "    the same but with shuffled labels.\n",
        "    Args:\n",
        "        X (torch.Tensor): batch of samples\n",
        "        Y (torch.Tensor): batch of labels\n",
        "        only_positive (bool): if True, it outputs only positive exmples with labels overlayed\n",
        "    Returns:\n",
        "        Tuple[torch.Tensor]: batch of positive (and negative samples)\n",
        "    \"\"\"\n",
        "    X_pos = X.clone()\n",
        "    X_pos[:, :10] *= 0.0\n",
        "    X_pos[range(X.shape[0]), Y] = X_pos.max()  # one hot\n",
        "    # X_pos[range(X.shape[0]), Y] = 1  # one hot\n",
        "\n",
        "    if only_positive:\n",
        "        return X_pos\n",
        "    else:\n",
        "        X_neg = X.clone()\n",
        "        rnd = torch.randperm(X_neg.size(0))\n",
        "        # Y_neg = (Y + torch.randint(1, (Y.max()-1), (Y.shape[0],))) % Y.max() # still don't get why does not work\n",
        "        Y_neg = Y[rnd]\n",
        "        X_neg[:, :10] *= 0.0\n",
        "        X_neg[range(X_neg.shape[0]), Y_neg] = X_neg.max()  # one hot\n",
        "\n",
        "        return X_pos, X_neg\n",
        "\n",
        "\n",
        "class TrainingDatasetFF(torch.utils.data.Dataset):\n",
        "    \"\"\"Utility class to store positive and negative examples to train\n",
        "       with FF algorithm.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_generator: DataLoader) -> None:\n",
        "        \"\"\"Initialize TrainingDatasetFF\n",
        "        Args:\n",
        "            dataset_generator (DataLoader): DataLoader to store\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            self.dataset = [\n",
        "                batch\n",
        "                for X_pos, X_neg in dataset_generator\n",
        "                for batch in zip(X_pos, X_neg)\n",
        "            ]\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        return self.dataset[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "pos_gen_fn = generate_positive_negative_samples_overlay\n",
        "train_loader_ff = torch.utils.data.DataLoader(TrainingDatasetFF(pos_gen_fn(X.to(device),Y.to(device), False) for X, Y in data_loader),\n",
        "                                              batch_size=data_loader.batch_size, shuffle=True\n",
        "                                              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "3Cd_d7KLTDfN"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ffl_list = []\n",
        "hidden_dimensions = [784, 2000, 2000, 2000, 2000,2000]\n",
        "for i in range(len(hidden_dimensions) - 1):\n",
        "    layer_ = FFLinear(hidden_dimensions[i], hidden_dimensions[i+1], activation = torch.nn.ReLU(), optimizer = torch.optim.Adam,\n",
        "                  layer_optim_learning_rate=0.09, threshold = 5.0, loss_fn = base_loss).to(device)\n",
        "    torch.nn.init.xavier_uniform_(layer_.weight)\n",
        "    ffl_list.append(layer_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gpwr9ydh12d",
        "outputId": "40f9f712-7165-4e4f-df04-cb589324f0e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[FFLinear(\n",
              "   in_features=784, out_features=2000, bias=True\n",
              "   (activation): ReLU()\n",
              " ),\n",
              " FFLinear(\n",
              "   in_features=2000, out_features=2000, bias=True\n",
              "   (activation): ReLU()\n",
              " ),\n",
              " FFLinear(\n",
              "   in_features=2000, out_features=2000, bias=True\n",
              "   (activation): ReLU()\n",
              " ),\n",
              " FFLinear(\n",
              "   in_features=2000, out_features=2000, bias=True\n",
              "   (activation): ReLU()\n",
              " )]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ffl_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9jcF9FCKN1P",
        "outputId": "4facb701-8d3e-493d-9a06-835516c16ca3"
      },
      "outputs": [],
      "source": [
        "# import tqdm\n",
        "\n",
        "# n_epochs = 1\n",
        "# tqdm_loss = tqdm.tqdm(range(n_epochs))\n",
        "# for epoch in tqdm_loss:\n",
        "#     loss_list = [[] for _ in range(len(ffl_list))]\n",
        "#     for X_pos, Y_neg in train_loader_ff:\n",
        "#         X_pos_tmp, Y_neg_tmp = X_pos, Y_neg\n",
        "#         for idx in range(len(ffl_list)):\n",
        "#             X_pos_tmp,Y_neg_tmp,layer_losses = ffl_list[idx].train_layer(X_pos_tmp.to(device), Y_neg_tmp.to(device), before=False)\n",
        "#             loss_list[idx].append(layer_losses)\n",
        "#             tqdm_loss.set_postfix({f\"loss{idx} \" : (sum(loss_list[idx])/len(loss_list[idx]))})\n",
        "        \n",
        "        # print(layer_losses, end='\\r')\n",
        "        # print(\", \".join(map(lambda i, l: 'Layer {}: {}'.format(i, l),list(range(len(layer_losses))) ,layer_losses)), end='\\r')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "K1GIVoij4MaL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [00:31<00:00,  1.89it/s, loss0 ={0.3995414674282074}] \n",
            "100%|██████████| 60/60 [00:33<00:00,  1.77it/s, loss1 ={0.2839842438697815}] \n",
            "100%|██████████| 60/60 [00:33<00:00,  1.77it/s, loss2 ={0.26600155234336853}]\n",
            "100%|██████████| 60/60 [00:33<00:00,  1.77it/s, loss3 ={0.3004131317138672}] \n",
            "100%|██████████| 60/60 [00:34<00:00,  1.76it/s, loss4 ={0.3065320551395416}] \n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "\n",
        "n_epochs = 60\n",
        "train_loader_ff = torch.utils.data.DataLoader(TrainingDatasetFF(pos_gen_fn(X.to(device),Y.to(device), False) for X, Y in data_loader),\n",
        "                                              batch_size=data_loader.batch_size, shuffle=True\n",
        "                                              )\n",
        "for idx in range(len(ffl_list)):\n",
        "    tqdm_loss = tqdm.tqdm(range(n_epochs))\n",
        "    for epoch in tqdm_loss:\n",
        "        loss_list = [[] for _ in range(len(ffl_list))]\n",
        "        \n",
        "        for X_pos, Y_neg in train_loader_ff:\n",
        "            X_pos_tmp, Y_neg_tmp = X_pos, Y_neg\n",
        "            _, _, layer_losses = ffl_list[idx].train_layer(X_pos_tmp,Y_neg_tmp, before=False)\n",
        "            tqdm_loss.set_postfix({f\"loss{idx} \" : {layer_losses}})\n",
        "            \n",
        "    traindatasetff  = TrainingDatasetFF(((ffl_list[idx](X_pos)), (ffl_list[idx](X_neg))) \n",
        "                                                                    for X_pos, X_neg in train_loader_ff)\n",
        "    train_loader_ff = torch.utils.data.DataLoader(traindatasetff,batch_size=data_loader.batch_size, shuffle=True)\n",
        "        \n",
        "        # print(layer_losses, end='\\r')\n",
        "        # print(\", \".join(map(lambda i, l: 'Layer {}: {}'.format(i, l),list(range(len(layer_losses))) ,layer_losses)), end='\\r')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "m8INBd5fNE5E"
      },
      "outputs": [],
      "source": [
        "def predict_goodness(layers, X, pos_gen_fn, n_class):\n",
        "    goodness_per_label = []\n",
        "    for label in range(n_class):\n",
        "        h = pos_gen_fn(X, label, True)\n",
        "        goodness = []\n",
        "        \n",
        "        for layer in layers:\n",
        "            h = layer(h)\n",
        "            goodness += [h.pow(2).mean(1)]\n",
        "        goodness_per_label += [sum(goodness).unsqueeze(1)]\n",
        "\n",
        "    goodness_per_label = torch.cat(goodness_per_label, 1)\n",
        "\n",
        "    return goodness_per_label.argmax(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP60BtPODr7v",
        "outputId": "2c87ae91-23b5-4479-db78-87f519546f0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 96.5400%\n",
            "Test error: 3.4600%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 97.1000%\n",
            "Test error: 2.9000%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 96.5600%\n",
            "Test error: 3.4400%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 95.9600%\n",
            "Test error: 4.0400%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 95.3200%\n",
            "Test error: 4.6800%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "layer_stack = []\n",
        "for layer in ffl_list:\n",
        "    acc = 0\n",
        "    layer_stack.append(layer)\n",
        "    for X_test, Y_test in tqdm.tqdm(test_loader, total=len(test_loader)):\n",
        "        X_test = X_test.to(device)\n",
        "        Y_test = Y_test.to(device)\n",
        "\n",
        "        acc += (predict_goodness(layer_stack,X_test,\n",
        "                pos_gen_fn, n_class=10).eq(Y_test).sum())\n",
        "\n",
        "    print(f\"Accuracy: {acc/float(len(test_loader.dataset)):.4%}\")\n",
        "    print(f\"Test error: {1 - acc/float(len(test_loader.dataset)):.4%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkngc2eeMgws",
        "outputId": "0c711901-136f-4f32-f3bb-8c20d9d527f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "e6pMuv96Mlbp",
        "outputId": "519f89e6-182d-4fd6-9558-a8c5e60e1624"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ca5c5ae32cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
          ]
        }
      ],
      "source": [
        "for X_test, Y_test in test_loader:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCCOtm-RM6LI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11 (tags/v3.9.11:2de452f, Mar 16 2022, 14:33:45) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c081257499a92776a7ff5343ee4d85420a7950a6ae97b0cb2aee7a7ddd41b7f2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
